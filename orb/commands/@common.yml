

build-docker-image:
  parameters:
    dockerfile:
      type: string
    path:
      description: The path to be used as the context when building the docker image. An empty directory is used by default.
      type: string
      default: ''
    identifier:
      type: string
    docker-hash-prefix:
      type: string
      default: v1
    tag:
      description: If provided, the given tag will be used for the docker image. By default a hash of the codebase (content of the path excluding files matched by .dockerignore) will be created.
      type: string
      default: ''
    expose_image:
      description: Whether to export an environment variable with the image name. This can be used by helm charts (currently only the frontend chart) to automatically adding the image reference to the release values.
      type: boolean
      default: true
  steps:
    - run:
        name: Build <<parameters.identifier>> docker image
        command: |
          image_url="$DOCKER_REPO_HOST/$DOCKER_REPO_PROJ/$NAMESPACE"-'<<parameters.identifier>>'

          # Only exclude files if they exist
          exclude_dockerignore=''
          if [ -f '<<parameters.path>>/.dockerignore' ]
          then
            exclude_dockerignore=--exclude-from='<<parameters.path>>'/.dockerignore
          fi

          if [ -n '<<parameters.path>>' ]; then
            path='<<parameters.path>>'
          else
            # No path is specified, build from an empty directory.
            mkdir /tmp/empty
            path='/tmp/empty'
          fi

          if [ -n '<<parameters.tag>>' ]; then
            # A tag has been specified, use it.
            image_tag="<<parameters.tag>>"
          else
            # Take a hash of all files in the folder except those ignored by docker.
            # Also make sure modification time or order play no role.
            image_tag=$(tar \
              --sort=name \
              $exclude_dockerignore \
              --exclude=vendor/composer \
              --exclude=vendor/autoload.php \
              --mtime='2000-01-01 00:00Z' \
              --clamp-mtime \
              -cf - $path '<<parameters.dockerfile>>' | sha1sum | cut -c 1-40)
            image_tag="<<parameters.docker-hash-prefix>>-$image_tag"
          fi

          if [ ! -z "$GCLOUD_KEY_JSON" ] && gcloud container images list-tags "$image_url" | grep -q "$image_tag"; then
            echo "Image $image_url:$image_tag has already been built, the existing image from the Docker repository will be used."
          
          elif [ ! -z "$AWS_SECRET_ACCESS_KEY" ] && aws ecr describe-images --repository-name="$DOCKER_REPO_PROJ/$NAMESPACE"-'<<parameters.identifier>>' --image-ids="imageTag=$image_tag" 2>&1 > /dev/null ; then
            echo "Image $image_url:$image_tag has already been built, the existing image from the Docker repository will be used."
          
          else
            docker build -t "$image_url:$image_tag" -f '<<parameters.dockerfile>>' $path

            if [ ! -z "$AWS_SECRET_ACCESS_KEY" ]
            then
              # Create repository (Because ECR requires a dedicated repository per project)
              if ! aws ecr describe-repositories --repository-name "$DOCKER_REPO_PROJ/$NAMESPACE"-'<<parameters.identifier>>' &>/dev/null ; then
                aws ecr create-repository --repository-name "$DOCKER_REPO_PROJ/$NAMESPACE"-'<<parameters.identifier>>'
              fi
            fi  

            docker push "$image_url:$image_tag"
          fi

          if [ '<<parameters.expose_image>>' = 'true' ]; then
            # Persist the image identifier and tag so it is available during deployment.
            echo "export <<parameters.identifier>>_IMAGE_IDENTIFIER='<<parameters.identifier>>'" >> "$BASH_ENV"
            echo "export <<parameters.identifier>>_HASH='$image_tag'" >> "$BASH_ENV"
          fi

docker-login:
  steps:
    - run:
        name: Login to the docker registry
        command: |
          if [ -z "$GCLOUD_KEY_JSON$AWS_SECRET_ACCESS_KEY" ]
          then
            echo "Cloud credentials \$GCLOUD_KEY_JSON or \$AWS_SECRET_ACCESS_KEY are empty, have you set a context for this CircleCI job correctly?"
          else
            # GCR login
            if [ ! -z "$GCLOUD_KEY_JSON" ]
            then
              printenv GCLOUD_KEY_JSON | docker login -u _json_key --password-stdin "https://$DOCKER_REPO_HOST"
            fi
            # ECR Login 
            if [ ! -z "$AWS_SECRET_ACCESS_KEY" ]
            then
              aws ecr get-login --no-include-email | bash
            fi
          fi

silta-setup:
  parameters:
    release-suffix:
      type: string
      default: ''
  steps:
    - setup_remote_docker:
        # Note: default Docker version is 17.09. Using BuildKit requires version 18.09 and dockerignore per dockerfile from 19.03
        version: 19.03.8
    - set-up-socks-proxy
    - cloud-login
    - docker-login
    - set-release-name:
        release-suffix: '<<parameters.release-suffix>>'

set-release-name:
  parameters:
    release-suffix:
      type: string
      default: ''
  steps:
    - run:
        name: Set release name
        command: |
          # Make sure namespace is lowercase.
          namespace="${CIRCLE_PROJECT_REPONAME,,}"

          # Create the namespace if it doesn't exist.
          if ! kubectl get namespace "$namespace" &>/dev/null ; then
            kubectl create namespace "$namespace"
          fi

          # Tag the namespace if it isn't already tagged.
          if ! kubectl get namespace -l name=$namespace --no-headers | grep $namespace &>/dev/null ; then
            kubectl label namespace "$namespace" "name=$namespace" --overwrite
          fi

          # Make sure release name is lowercase without special characters.
          branchname_lower="${CIRCLE_BRANCH,,}"
          release_name="${branchname_lower//[^[:alnum:]]/-}"

          # If name is too long, truncate it and append a hash
          if [ ${#release_name} -ge 40 ]; then
            release_name="$(printf "$release_name" | cut -c 1-35)-$(printf "$branchname_lower" | shasum -a 256 | cut -c 1-4 )"
          fi

          silta_environment_name="${CIRCLE_BRANCH,,}"

          if [[ -n '<<parameters.release-suffix>>' ]]; then
            release_name="${release_name}-<<parameters.release-suffix>>"
            silta_environment_name="${CIRCLE_BRANCH,,}-<<parameters.release-suffix>>"
          fi


          echo "export RELEASE_NAME='$release_name'" >> "$BASH_ENV"
          echo "export NAMESPACE='$namespace'" >> "$BASH_ENV"
          echo "export SILTA_ENVIRONMENT_NAME='$silta_environment_name'" >> "$BASH_ENV"

          echo "The release name for this branch is \"$release_name\" in the \"$namespace\" namespace"

          if helm status -n "$namespace" "$release_name" > /dev/null  2>&1
          then
            current_chart_version=$(helm history -n "$namespace" "$release_name" --max 1 --output json | jq -r '.[].chart')
            echo "export CURRENT_CHART_VERSION='$current_chart_version'" >> "$BASH_ENV"

            echo "There is an existing chart with version $current_chart_version"
          fi

# This will be deprecated in favor of cloud-login job
gcloud-login:
  description: Replace this with cloud-login job!
  steps:
    - cloud-login

cloud-login:
  steps:
    - run:
        name: Cloud login
        command: |
          if [ ! -z "$GCLOUD_KEY_JSON" ]
          then
            # Save key, authenticate and set compute zone.
            printenv GCLOUD_KEY_JSON > "$HOME/gcloud-service-key.json"
            gcloud auth activate-service-account --key-file="$HOME/gcloud-service-key.json" --project "$GCLOUD_PROJECT_NAME"

            if [[ -n "$GCLOUD_COMPUTE_REGION" ]]; then
              location="--region $GCLOUD_COMPUTE_REGION"
            else
              location="--zone $GCLOUD_COMPUTE_ZONE"
            fi

            # Updates a kubeconfig file with appropriate credentials and endpoint information.
            gcloud container clusters get-credentials "$GCLOUD_CLUSTER_NAME" $location --project "$GCLOUD_PROJECT_NAME"

          elif [ ! -z "$AWS_SECRET_ACCESS_KEY" ]
          then
            aws eks update-kubeconfig --name $GCLOUD_CLUSTER_NAME --region $AWS_REGION
          fi

helm-cleanup:
  steps:
    - run:
        name: Clean up failed Helm releases
        command: |
          failed_revision=$(helm list -n "$NAMESPACE" --failed --pending --filter="(\s|^)($RELEASE_NAME)(\s|$)" | tail -1 | cut -f3)

          if [[ "$failed_revision" -eq 1 ]]; then
            # Remove any existing post-release hook, since it's technically not part of the release.
            kubectl delete job -n "$NAMESPACE" "$RELEASE_NAME-post-release" 2> /dev/null || true

            echo "Removing failed first release."
            helm delete -n "$NAMESPACE" "$RELEASE_NAME"

            echo "Delete persistent volume claims left over from statefulsets."
            kubectl delete pvc -n "$NAMESPACE" -l release="$RELEASE_NAME"
            kubectl delete pvc -n "$NAMESPACE" -l app="$RELEASE_NAME-es"

            echo -n "Waiting for volumes to be deleted."
            until [[ -z `kubectl get pv | grep "$NAMESPACE/$RELEASE_NAME-"` ]]
            do
              echo -n "."
              sleep 5
            done
          fi

helm-release-information:
  steps:
    - run:
        name: Release information
        command: |
          # Display only the part following NOTES from the helm status.
          helm -n "$NAMESPACE" get notes "$RELEASE_NAME"
    - run:
        name: Post release info to Github
        command: |
          if [ -n "$GITHUB_TOKEN" ]
          then
            RELEASE_NOTES=`helm -n "$NAMESPACE" get notes "$RELEASE_NAME"`
            if [ -z "$CIRCLE_PR_NUMBER" ]
            then
              CIRCLE_PR_NUMBER="${CIRCLE_PULL_REQUEST//[^0-9]/}"
            fi
            GITHUB_API_URL="https://api.github.com/repos/$CIRCLE_PROJECT_USERNAME/$CIRCLE_PROJECT_REPONAME/issues/$CIRCLE_PR_NUMBER/comments"
            FORMATTED_NOTES=$(echo "$RELEASE_NOTES" | sed 's/\\/\\\\/g' | sed 's/"/\\\"/g' | sed 's/\$/\\n/g' | sed 's/\//\\\//g')
            curl -H "Authorization: token $GITHUB_TOKEN" -H "Content-Type: application/json" -X POST -d '{"body": "<details><summary>Release notes for '$RELEASE_NAME'</summary>'"${FORMATTED_NOTES//$'\n'/'\n'}"'</details>"}' $GITHUB_API_URL
          fi

decrypt-files:
  parameters:
    files:
      type: string
    secret_key_env:
      type: env_var_name
      default: SECRET_KEY
  steps:
    - run:
        name: Decrypt secret files
        command: |
          # Secret management
          secrets='<<parameters.files>>'
          if [[ ! -z "$secrets" ]]; then
            echo "Decrypting secrets"
            for file in ${secrets//,/}
            do
              echo "$file"
              tmp=$(mktemp)
              openssl enc -d -aes-256-cbc -pbkdf2 -in "$file" -out "$tmp" -pass env:<<parameters.secret_key_env>>
              mv -v "$tmp" "$file"
              chmod a+r "$file"
            done
          fi

set-up-socks-proxy:
  steps:
    - run:
        name: Add SSH private-key
        command: |
          if [[ -n "$TUNNEL_PRIVATE_KEY" ]]; then
            echo -e "$TUNNEL_PRIVATE_KEY" | tr -d '\r' | ssh-add - > /dev/null
          fi    
    - run:
        name: Open up a tunnel
        command: |
          if [[ -n "$TUNNEL_USER_HOST" ]]; then
            ssh -o StrictHostKeyChecking=accept-new -D 1337 -C -N -q -f "$TUNNEL_USER_HOST"
            echo 'export HTTPS_PROXY=socks5://localhost:1337' >> $BASH_ENV
            gcloud config set proxy/type socks5
            gcloud config set proxy/address 127.0.0.1
            gcloud config set proxy/port 1337
            echo "Proxy is ready for outgoing connections"
          fi

