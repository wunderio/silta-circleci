version: 2.1
description: "A collection of CircleCI tools used by the Silta hosting infrastructure."

# CircleCI executors
executors:
  silta:
    docker:
      - image: wunderio/silta-circleci:v0.1

# CircleCI Jobs
jobs:
  drupal-validate:
    executor: <<parameters.executor>>
    parameters:
      executor:
        description: The name of custom executor to use
        type: executor
        default: silta
      drupal-root:
        type: string
        default: "."
      pre-validation:
        type: steps
        default: []
      post-validation:
        type: steps
        default: []
    working_directory: ~/project/<<parameters.drupal-root>>
    steps:
      - checkout:
          path: ~/project
      - steps: <<parameters.pre-validation>>
      - drupal-composer-install:
          install-dev-dependencies: true
      - phpcs
      - grumphp
      - run:
          name: Silta basic checks
          command: |
            files=(
              silta/silta.yml
              silta/silta-prod.yml
              silta/nginx.Dockerfile
              silta/php.Dockerfile
              silta/shell.Dockerfile
              .dockerignore
              web/.dockerignore
            )

            for file in "${files[@]}"; do
              if [ -f "$file" ]; then
                echo "✅ $file is present"
              else
                echo "❌ $file is missing from the repository."
                exit 1
              fi
            done

            if grep "drush.*8" composer.json; then
              echo "❌ Silta is not compatible with drush 8."
            fi

      - steps: <<parameters.post-validation>>

  drupal-build-deploy:
    executor: <<parameters.executor>>
    parameters:
      executor:
        description: The name of custom executor to use
        type: executor
        default: silta
      drupal-root:
        type: string
        default: "."
      codebase-build:
        type: steps
        default: []
      pre-release:
        description: Steps to be executed before the Helm release is created.
        type: steps
        default: []
      chart_name:
        type: string
        default: drupal
      chart_repository:
        type: string
        default: https://storage.googleapis.com/charts.wdr.io
      decrypt_files:
        type: string
        default: ""
      silta_config:
        type: string
        default: "silta/silta.yml"
      skip-deployment:
        type: boolean
        default: false
      cluster_domain:
        type: env_var_name
        default: CLUSTER_DOMAIN
    working_directory: ~/project/<<parameters.drupal-root>>
    steps:
      - checkout:
          path: ~/project
      - steps: <<parameters.codebase-build>>
      - unless:
          condition: <<parameters.skip-deployment>>
          steps:
            - gcloud-login
            - when:
                condition: <<parameters.decrypt_files>>
                steps:
                  - decrypt-files:
                      files: <<parameters.decrypt_files>>
            - drupal-docker-build
            - set-release-name
            - steps: <<parameters.pre-release>>
            - drupal-helm-deploy:
                chart_name: <<parameters.chart_name>>
                chart_repository: <<parameters.chart_repository>>
                silta_config: <<parameters.silta_config>>
                cluster_domain: <<parameters.cluster_domain>>

  frontend-build-deploy:
    executor: <<parameters.executor>>
    parameters:
      executor:
        description: The name of custom executor to use
        type: executor
        default: silta
      codebase-build:
        type: steps
        default: []
      chart_name:
        type: string
        default: frontend
      chart_repository:
        type: string
        default: https://storage.googleapis.com/charts.wdr.io
      silta_config:
        type: string
        default: "silta/silta.yml"
      skip-deployment:
        type: boolean
        default: false
      cluster_domain:
        type: env_var_name
        default: CLUSTER_DOMAIN
      image_build_steps:
        type: steps
        default: 
        - build-docker-image:
            dockerfile: 'silta/node.Dockerfile'
            path: '.'
            identifier: 'node'
    steps:
      - checkout

      - steps: <<parameters.codebase-build>>

      - setup_remote_docker

      - gcloud-login

      - docker-login

      - steps: <<parameters.image_build_steps>>

      - unless:
          condition: <<parameters.skip-deployment>>
          steps:
            - set-release-name

            - helm-cleanup

            - run:
                name: Deploy helm release
                command: |
                  reponame="${CIRCLE_PROJECT_REPONAME,,}"
                  image_overrides=""
                  for var in `env | grep _IMAGE_IDENTIFIER`; do
                    identifier=`echo $var | cut -f 2 -d "="`
                    image_url="$DOCKER_REPO_HOST/$DOCKER_REPO_PROJ/$reponame-$identifier"
                    image_tag="${identifier}_HASH"
                    image_overrides="$image_overrides --set services.${identifier}.image=${image_url}:${!image_tag}"
                  done
                  
                  # Add internal VPN if defined in environment
                  extra_noauthips=""
                  if [[ ! -z "$VPN_IP" ]] ; then
                    extra_noauthips="--set nginx.noauthips.vpn=${VPN_IP}/32"
                  fi
                  
                  helm upgrade --install "$RELEASE_NAME" '<<parameters.chart_name>>' \
                    --repo '<<parameters.chart_repository>>' \
                    --set environmentName="$CIRCLE_BRANCH" \
                    $extra_noauthips \
                    $image_overrides \
                    --set shell.gitAuth.repositoryUrl="$CIRCLE_REPOSITORY_URL" \
                    --set shell.gitAuth.apiToken="$GITAUTH_API_TOKEN" \
                    --set clusterDomain=${<<parameters.cluster_domain>>} \
                    --namespace="$reponame" \
                    --values '<<parameters.silta_config>>'
            - run:
                name: Wait for resources to be ready
                command: |
                  reponame="${CIRCLE_PROJECT_REPONAME,,}"
                  # Get all deployments in the release and check the status of each one.
                  kubectl get deployment -n "$reponame" -l "release=${RELEASE_NAME}" -o name | xargs -n 1 kubectl rollout status -n "$reponame"

            - helm-release-information


  simple-build-deploy:
    executor: <<parameters.executor>>
    parameters:
      executor:
        description: The name of custom executor to use
        type: executor
        default: silta
      codebase-build:
        type: steps
        default: []
      chart_name:
        type: string
        default: simple
      chart_repository:
        type: string
        default: https://storage.googleapis.com/charts.wdr.io
      silta_config:
        type: string
        default: "silta/silta.yml"
      skip-deployment:
        type: boolean
        default: false
      cluster_domain:
        type: env_var_name
        default: CLUSTER_DOMAIN

    steps:
      - checkout

      - steps: <<parameters.codebase-build>>

      - setup_remote_docker

      - gcloud-login

      - docker-login

      - build-docker-image:
          dockerfile: 'silta/nginx.Dockerfile'
          path: 'public'
          identifier: 'nginx'

      - unless:
          condition: <<parameters.skip-deployment>>
          steps:
            - set-release-name

            - helm-cleanup

            - run:
                name: Deploy helm release
                command: |
                  reponame="${CIRCLE_PROJECT_REPONAME,,}"

                  # Add internal VPN if defined in environment
                  extra_noauthips=""
                  if [[ ! -z "$VPN_IP" ]] ; then
                    extra_noauthips="--set nginx.noauthips.vpn=${VPN_IP}/32"
                  fi

                  helm upgrade --install "$RELEASE_NAME" '<<parameters.chart_name>>' \
                    --repo '<<parameters.chart_repository>>' \
                    --set environmentName="$CIRCLE_BRANCH" \
                    $extra_noauthips \
                    --set clusterDomain=${<<parameters.cluster_domain>>} \
                    --set nginx.image=$DOCKER_REPO_HOST/$DOCKER_REPO_PROJ/${CIRCLE_PROJECT_REPONAME,,}-nginx:$nginx_HASH \
                    --namespace="$reponame" \
                    --values '<<parameters.silta_config>>' \
                    --wait

            - helm-release-information

# CircleCI commands
commands:
  phpcs:
    steps:
      - run:
          name: phpcs validation
          command: |
            if [ -f phpcs.xml ] && [ -f vendor/bin/phpcs ]; then
              vendor/bin/phpcs --standard=phpcs.xml -s --colors
            fi

  grumphp:
    steps:
      - run:
          name: grumphp validation
          command: |
            if [ -f grumphp.yml ] && [ -f vendor/bin/grumphp ]; then
              grumphp run
            fi

  drupal-composer-install:
    parameters:
      install-dev-dependencies:
        type: boolean
        default: false
    steps:
      - restore_cache:
          keys:
            - v1-dependencies-{{ checksum "composer.lock" }}-<<parameters.install-dev-dependencies>>
            - v1-dependencies-{{ checksum "composer.lock" }}

      - when:
          condition: <<parameters.install-dev-dependencies>>
          steps:
            - run:
                name: composer install
                command: |
                  composer install -n --prefer-dist --ignore-platform-reqs --optimize-autoloader

      - unless:
          condition: <<parameters.install-dev-dependencies>>
          steps:
            - run:
                name: composer install
                command: |
                  composer install -n --prefer-dist --ignore-platform-reqs --no-dev --optimize-autoloader

      - save_cache:
          paths:
            - ./vendor
            - ./web/core
            - ./web/modules/contrib
            - ./web/themes/contrib
            - ./web/profiles/contrib
            - ./web/libraries
          key: v1-dependencies-{{ checksum "composer.lock" }}-<<parameters.install-dev-dependencies>>

  # Deprecated in favor of the yarn-install-build command, or even better switch to npm and use npm-install-build.
  yarn-install:
    parameters:
      cache-version:
        type: string
        default: "v1"
    steps:
      - restore_cache:
          keys:
            - <<parameters.cache-version>>-yarn-{{ checksum "yarn.lock" }}
            - <<parameters.cache-version>>-yarn-

      - run: yarn install

      - save_cache:
          paths:
            - node_modules
          key: <<parameters.cache-version>>-yarn-{{ checksum "yarn.lock" }}

  build-docker-image:
    parameters:
      dockerfile:
        type: string
      path:
        type: string
      identifier:
        type: string
      docker-hash-prefix:
        type: string
        default: v1
    steps:
      - run:
          name: Build <<parameters.identifier>> docker image
          command: |
            image_url="$DOCKER_REPO_HOST/$DOCKER_REPO_PROJ/${CIRCLE_PROJECT_REPONAME,,}"-'<<parameters.identifier>>'

            # Only exclude files
            exclude_dockerignore=''
            if [ -f '<<parameters.path>>/.dockerignore' ]
            then
              exclude_dockerignore=--exclude-from='<<parameters.path>>'/.dockerignore
            fi

            # Take a hash of all files in the folder except those ignored by docker.
            # Also make sure modification time or order play no role.
            image_tag=$(tar \
              --sort=name \
              $exclude_dockerignore \
              --exclude=vendor/composer \
              --exclude=vendor/autoload.php \
              --mtime='2000-01-01 00:00Z' \
              --clamp-mtime \
              -cf - '<<parameters.path>>' '<<parameters.dockerfile>>' | sha1sum | cut -c 1-40)
            image_tag="<<parameters.docker-hash-prefix>>-$image_tag"

            if gcloud container images list-tags "$image_url" | grep -q "$image_tag"; then
              echo "This <<parameters.identifier>> image has already been built, the existing image from the Docker repository will be used."
            else
              docker build -t "$image_url:$image_tag" -f '<<parameters.dockerfile>>' '<<parameters.path>>'
              docker push "$image_url:$image_tag"
            fi

            # Persist the image identifier and tag so it is available during deployment.
            echo "export <<parameters.identifier>>_IMAGE_IDENTIFIER='<<parameters.identifier>>'" >> "$BASH_ENV"
            echo "export <<parameters.identifier>>_HASH='$image_tag'" >> "$BASH_ENV"
            
            


  npm-install-build:
    parameters:
      path:
        type: string
        default: "."
      build-command:
        type: string
        default: "npm run build"
      cache-version:
        type: string
        default: "v1"
    steps:
      - restore_cache:
          keys:
            - <<parameters.cache-version>>-npm-{{ checksum "<<parameters.path>>/package-lock.json" }}
            - <<parameters.cache-version>>-npm-

      - run:
          name: Install frontend dependencies
          command: |
            cd '<<parameters.path>>'
            npm install

      - run:
          name: Build frontend
          command: |
            cd '<<parameters.path>>'
            <<parameters.build-command>>

      - save_cache:
          paths:
            - <<parameters.path>>/node_modules
          key: <<parameters.cache-version>>-npm-{{ checksum "<<parameters.path>>/package-lock.json" }}

  yarn-install-build:
    parameters:
      path:
        type: string
        default: "."
      build-command:
        type: string
        default: "yarn build"
      cache-version:
        type: string
        default: "v1"
    steps:
      - restore_cache:
          keys:
            - <<parameters.cache-version>>-yarn-{{ checksum "<<parameters.path>>/yarn.lock" }}
            - <<parameters.cache-version>>-yarn-

      - run:
          name: Install frontend dependencies
          command: |
            cd '<<parameters.path>>'
            yarn install

      - run:
          name: Build frontend
          command: |
            cd '<<parameters.path>>'
            <<parameters.build-command>>

      - save_cache:
          paths:
            - <<parameters.path>>/node_modules
          key: <<parameters.cache-version>>-yarn-{{ checksum "<<parameters.path>>/yarn.lock" }}

  docker-login:
    steps:
      - run:
          name: Login to the docker registry
          command: |
            if [ -z "$GCLOUD_KEY_JSON" ]
            then
              echo "\$GCLOUD_KEY_JSON is empty, have you set a context for this CircleCI job?"
            else
              printenv GCLOUD_KEY_JSON | docker login -u _json_key --password-stdin "https://$DOCKER_REPO_HOST"
            fi

  drupal-docker-build:
    steps:
      - setup_remote_docker

      - docker-login

      - build-docker-image:
          dockerfile: silta/nginx.Dockerfile
          path: web
          identifier: nginx

      - build-docker-image:
          dockerfile: silta/php.Dockerfile
          path: "."
          identifier: php

      - build-docker-image:
          dockerfile: silta/shell.Dockerfile
          path: "."
          identifier: shell

  set-release-name:
    steps:
      - run:
          name: Set release name
          command: |
            # Release name length is 37 chars long, which leaves max 16 chars for kubernetes resource name.
            # Release name is prefixed with w because  it _HAS_ to start with alphabetic character. w 4 wunder.
            branchname_lower="${CIRCLE_BRANCH,,}"
            branchname="${branchname_lower//[^[:alnum:]]/-}"
            branchname_hash=$(printf "$branchname" | shasum -a 256 | cut -c 1-4 )
            branchname_truncated=$(printf "$branchname" | cut -c 1-15 | sed 's/^\(.*\)-$/\1/' )
            reponame="${CIRCLE_PROJECT_REPONAME,,}"
            reponame_hash=$(printf "$reponame" | shasum -a 256 | cut -c 1-4 )
            reponame_truncated=$(printf "$reponame" | cut -c 1-15 | sed 's/^\(.*\)-$/\1/' )
            # Truncate long names
            if [ ${#branchname} -ge 20 ]; then branchname="$branchname_truncated-$branchname_hash"; fi
            if [ ${#reponame} -ge 20 ]; then reponame="$reponame_truncated-$reponame_hash"; fi
            name="$reponame--$branchname"
            echo "export RELEASE_NAME='$name'" >> "$BASH_ENV"

            echo "The release name for this branch is $name"

  gcloud-login:
    steps:
      - run:
          name: Google Cloud login
          command: |
            # Save key, authenticate and set compute zone.
            printenv GCLOUD_KEY_JSON > "$HOME/gcloud-service-key.json"
            gcloud auth activate-service-account --key-file="$HOME/gcloud-service-key.json" --project "$GCLOUD_PROJECT_NAME"
            gcloud config set compute/zone "$GCLOUD_COMPUTE_ZONE"

            # Updates a kubeconfig file with appropriate credentials and endpoint information.
            gcloud container clusters get-credentials "$GCLOUD_CLUSTER_NAME" --zone "$GCLOUD_COMPUTE_ZONE" --project "$GCLOUD_PROJECT_NAME"

  helm-cleanup:
    steps:
      - run:
          name: Clean up failed Helm releases
          command: |
            reponame="${CIRCLE_PROJECT_REPONAME,,}"

            if [[ $( helm list --failed "$RELEASE_NAME" | tail -1 | cut -f2 ) -eq 1 ]]; then
              # Remove any existing post-release hook, since it's technically not part of the release.
              kubectl delete job -n "$reponame" "$RELEASE_NAME-post-release" 2> /dev/null || true

              echo "Removing failed first release."
              helm delete --purge "$RELEASE_NAME"

              echo "Delete persistent volume claims left over from statefulsets."
              kubectl get pvc -n "$reponame" -l release="$RELEASE_NAME" -o name | xargs -n 1 kubectl delete --ignore-not-found=true -n "$reponame"

              echo -n "Waiting for volumes to be deleted."
              until [[ -z `kubectl get pv | grep "$RELEASE_NAME-public-files"` ]]
              do
                echo -n "."
                sleep 5
              done
            fi

  helm-release-information:
    steps:
      - run:
          name: Release information
          command: |
            # Display only the part following NOTES from the helm status.
            helm status "$RELEASE_NAME" | sed -e '1,/NOTES/d'

  decrypt-files:
    parameters:
      files:
        type: string
      secret_key_env:
        type: env_var_name
        default: SECRET_KEY
    steps:
      - run:
          name: Decrypt secret files
          command: |
            # Secret management
            secrets='<<parameters.files>>'
            if [[ ! -z "$secrets" ]]; then
              echo "Decrypting secrets"
              for file in ${secrets//,/}
              do
                echo "$file"
                tmp=$(mktemp)
                openssl enc -d -aes-256-cbc -pbkdf2 -in "$file" -out "$tmp" -pass env:<<parameters.secret_key_env>>
                mv -v "$tmp" "$file"
                chmod a+r "$file"
              done
            fi

  drupal-helm-deploy:
    parameters:
      chart_name:
        type: string
      chart_repository:
        type: string
      silta_config:
        type: string
      cluster_domain:
        type: env_var_name
        default: CLUSTER_DOMAIN
    steps:
      - helm-cleanup
      - run:
          name: Deploy helm release
          command: |
            reponame="${CIRCLE_PROJECT_REPONAME,,}"

            # Disable reference data if the required volume is not present.
            reference_volume=$(kubectl get pv | grep --extended-regexp "$reponame/.*-reference-data") || true
            reference_data_override=''
            if [[ -z "$reference_volume" ]] ; then
              reference_data_override='--set referenceData.skipMount=true'
            fi

            # echo $WHITELISTED_IPS

            # Override Database credentials if specified
            if [[ ! -z "$DB_ROOT_PASS" ]] ; then
              db_root_pass_override="--set mariadb.rootUser.password=$DB_ROOT_PASS"
            fi
            if [[ ! -z "$DB_USER_PASS" ]] ; then
              db_user_pass_override="--set mariadb.db.password=$DB_USER_PASS"
            fi
            
            # Add internal VPN if defined in environment
            extra_noauthips=""
            if [[ ! -z "$VPN_IP" ]] ; then
              extra_noauthips="--set nginx.noauthips.vpn=${VPN_IP}/32"
            fi

            output=$((helm upgrade --install "$RELEASE_NAME" '<<parameters.chart_name>>' \
              --repo '<<parameters.chart_repository>>' \
              --set environmentName="$CIRCLE_BRANCH" \
              --set php.image="$DOCKER_REPO_HOST/$DOCKER_REPO_PROJ/$reponame-php:$php_HASH" \
              --set nginx.image="$DOCKER_REPO_HOST/$DOCKER_REPO_PROJ/$reponame-nginx:$nginx_HASH" \
              --set shell.image="$DOCKER_REPO_HOST/$DOCKER_REPO_PROJ/$reponame-shell:$shell_HASH" \
              $extra_noauthips \
              $db_root_pass_override \
              $db_user_pass_override \
              --set shell.gitAuth.repositoryUrl="$CIRCLE_REPOSITORY_URL" \
              --set shell.gitAuth.apiToken="$GITAUTH_API_TOKEN" \
              --set clusterDomain="${<<parameters.cluster_domain>>}" \
              $reference_data_override \
              --namespace="$reponame" \
              --values '<<parameters.silta_config>>' \
              --timeout 600) 2>&1) || EXIT_CODE=$?

            if [[ $output == *"BackoffLimitExceeded"* ]]; then
              # Don't show BackoffLimitExceeded, it confuses everyone.
              echo "The post-release job failed, see log output in the next step below."
            else
              echo "$output"
            fi

            exit $EXIT_CODE

      - run:
          name: Deployment log
          when: always
          command: |
            reponame="${CIRCLE_PROJECT_REPONAME,,}"
            kubectl logs "job/$RELEASE_NAME-post-release" -n "$reponame" -f --timestamps=true

      - run:
          name: Wait for resources to be ready
          command: |
            reponame="${CIRCLE_PROJECT_REPONAME,,}"
            # Get all deployments and statefulsets in the release and check the status of each one.
            kubectl get statefulset -n "$reponame" -l "release=${RELEASE_NAME}" -o name | xargs -n 1 kubectl rollout status -n "$reponame"
            kubectl get deployment -n "$reponame" -l "release=${RELEASE_NAME}" -o name | xargs -n 1 kubectl rollout status -n "$reponame"
            
      - helm-release-information

  gatsby-move-to-subfolder:
    parameters:
      subfolder_name:
        type: string
      build_folder:
        type: string
        default: public
    steps:
      - run:
          name: Move to subfolder
          command: |
            mv <<parameters.build_folder>> <<parameters.subfolder_name>>
            mkdir <<parameters.build_folder>>
            mv <<parameters.subfolder_name>> <<parameters.build_folder>>/<<parameters.subfolder_name>>
            mv <<parameters.build_folder>>/<<parameters.subfolder_name>>/.dockerignore <<parameters.build_folder>>/.dockerignore
            echo '<meta http-equiv="refresh" content="0; URL=<<parameters.subfolder_name>>" />' > <<parameters.build_folder>>/index.html

  gatsby-google-cloud-storage-deploy:
    parameters:
      bucket_name:
        type: string
      build_folder:
        type: string
        default: public
      static_files:
        type: string
        default: static
    steps:
      - run:
          name: Deploy to Google Cloud Storage
          command: |
            cd <<parameters.build_folder>>
            # We need this rsync mainly to delete obsolete files, but without downtime.
            gsutil -m -h "Cache-Control:public, max-age=300" rsync -d -r . <<parameters.bucket_name>>
            # Make sure all text files can be served gzipped. This is unfortunately not possible with the rsync command.
            gsutil -m -h "Cache-Control:public, max-age=300" cp -z html,css,js -r . <<parameters.bucket_name>>
            # Set a longer cache time for all files in the static folder.
            gsutil -m setmeta -r -h "Cache-Control:public, max-age=31536000" <<parameters.bucket_name>>/<<parameters.static_files>>